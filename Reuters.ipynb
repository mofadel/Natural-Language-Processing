{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label classification on Reuters dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to deal with a multi-label classification problem. The dataset we are using is `Reuters` which contains newswire articles with 90 categories. The dataset has 7769 records for training and 3019 for test, and it is available on `nltk.corpus`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters ##import the corpus from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 10788\n",
      "Number of training examples: 7769\n",
      "Number of test examples: 3019\n",
      "Number of categories: 90\n"
     ]
    }
   ],
   "source": [
    "documents_ids = reuters.fileids() #in the format type/num_doc(e.g. training/1000)\n",
    "print(\"Number of documents: {}\".format(len(documents_ids)))\n",
    "\n",
    "#Number of training examples\n",
    "training_examples = list(filter(lambda doc: doc.startswith('training'),documents_ids))\n",
    "print(\"Number of training examples: {}\".format(len(training_examples)))\n",
    "\n",
    "#Number of test examples\n",
    "test_examples = list(filter(lambda doc: doc.startswith('test'),documents_ids))\n",
    "print(\"Number of test examples: {}\".format(len(test_examples)))\n",
    "\n",
    "#Number of categories\n",
    "print(\"Number of categories: {}\".format(len(reuters.categories())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every document is in the form `content - categories`. Let us visualize one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:  N.Z. TRADING BANK DEPOSIT GROWTH RISES SLIGHTLY\n",
      "  New Zealand's trading bank seasonally\n",
      "  adjusted deposit growth rose 2.6 pct in January compared with a\n",
      "  rise of 9.4 pct in December, the Reserve Bank said.\n",
      "      Year-on-year total deposits rose 30.6 pct compared with a\n",
      "  26.3 pct increase in the December year and 34.5 pct rise a year\n",
      "  ago period, it said in its weekly statistical release.\n",
      "      Total deposits rose to 17.18 billion N.Z. Dlrs in January\n",
      "  compared with 16.74 billion in December and 13.16 billion in\n",
      "  January 1986.\n",
      "  \n",
      "\n",
      "\n",
      "Categorie(s):  ['money-supply']\n"
     ]
    }
   ],
   "source": [
    "oneDoc = 'training/100'\n",
    "print('Content: ',reuters.raw(oneDoc)) #It outputs the content of the document in one string\n",
    "print('Categorie(s): ',reuters.categories(oneDoc)) #It outputs the categorie(s) of one document in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most common categories are : [('earn', 3926), ('acq', 2369), ('crude', 552), ('interest', 453), ('money-fx', 362)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "categories =[]\n",
    "for doc in documents_ids:\n",
    "    categories.append(reuters.categories(doc)[0])\n",
    "\n",
    "dict_categories = Counter(categories)\n",
    "print('The 5 most common categories are :',dict_categories.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stop_words = stopwords.words('english')         # set of stopwords that we will remove in the documents\n",
    "tf_vectorizer = TfidfVectorizer(stop_words, max_features=20000, use_idf=True)     # define the vectorizer\n",
    "\n",
    "train_docs = [reuters.raw(doc) for doc in training_examples] # get the training documents\n",
    "test_docs = [reuters.raw(doc) for doc in test_examples]      # get the test documents\n",
    "\n",
    "vectorized_train_docs = tf_vectorizer.fit_transform(train_docs) # embedding of the training documents\n",
    "vectorized_test_docs = tf_vectorizer.transform(test_docs)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# stop_words = stopwords.words('english')         # set of stopwords that we will remove in the documents\n",
    "# vectorizer = CountVectorizer(stop_words)     # define the vectorizer\n",
    "\n",
    "# train_docs = [reuters.raw(doc) for doc in training_examples] # get the training documents\n",
    "# test_docs = [reuters.raw(doc) for doc in test_examples]      # get the test documents\n",
    "\n",
    "# vectorized_train_docs = vectorizer.fit_transform(train_docs) # embedding of the training documents\n",
    "# vectorized_test_docs = vectorizer.transform(test_docs)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform([reuters.categories(doc) for doc in training_examples])\n",
    "test_labels = mlb.transform([reuters.categories(doc) for doc in test_examples])\n",
    "\n",
    "#OvR = OneVsRestClassifier(LogisticRegression(C=1, solver='sag', max_iter = 10000))\n",
    "OvR = OneVsRestClassifier(LinearSVC(random_state=123))\n",
    "OvR.fit(vectorized_train_docs, train_labels)\n",
    "pred_labels = OvR.predict(vectorized_test_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.8068896985756873\n",
      "Precision Score:  0.9476205685084638\n",
      "F1 Score:  0.8631272727272727\n",
      "Recall Score:  0.7924679487179487\n",
      "ROC_AUC Score:  0.8959279653876869\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score\n",
    "print('Accuracy Score: ', accuracy_score(test_labels,pred_labels))\n",
    "print('Precision Score: ', precision_score(test_labels, pred_labels, average='micro'))\n",
    "print('F1 Score: ', f1_score(test_labels, pred_labels,average='micro'))\n",
    "print('Recall Score: ',recall_score(test_labels, pred_labels,average='micro'))\n",
    "print('ROC_AUC Score: ',roc_auc_score(test_labels, pred_labels, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
